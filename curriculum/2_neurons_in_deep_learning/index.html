<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>1.2 Neurons in Deep Learning | SAIL Team Interpretability</title> <meta name="author" content="SAIL Team Interpretability"> <meta name="description" content="📙 Chapter 1. Neuron &lt;br&gt; &lt;em&gt; How can we interpret neurons in deep learning?&lt;/em&gt;"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://team-interpret.github.io/curriculum/2_neurons_in_deep_learning/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "1.2 Neurons in Deep Learning",
      "description": "📙 Chapter 1. Neuron <br> <em> How can we interpret neurons in deep learning?</em>",
      "published": "August 14, 2023",
      "authors": [
        {
          "author": "Bumjin Park",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Enver Menadjiev",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        },
        {
          "author": "Youngju Joung",
          "authorURL": "",
          "affiliations": [
            {
              "name": "KAIST",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a href="http://sailab.kaist.ac.kr/" rel="external nofollow noopener" target="_blank"> <img src="/assets/img/sail_logo_white.png" width="80px" style="margin-right:20px; margin-left:-100px; padding-bottom: 0px; border: solid #737ea3 1px; border-radius: 10px;"> </a> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">SAIL </span>Team Interpretability</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/curriculum/">Curriculum</a> </li> <li class="nav-item "> <a class="nav-link" href="/ts/">TS</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>1.2 Neurons in Deep Learning</h1> <p>📙 Chapter 1. Neuron <br> <em> How can we interpret neurons in deep learning?</em></p> </d-title> <d-byline></d-byline> <d-article> <h2 id="introduction">Introduction</h2> <p>In the previous section, we introduced neurons in deep learning by comparing neurons in neuroscience. The previous section only introduced neurons in a linear weight and bias. With the same interpretation, we introduce several neurons in deep learning modules including multi layer perceptron (MLP), convolutional neural network (CNN), recurrent neural network, and generative pretrained models (GPT). In addition, we also provide a neuron perspective on key-value memory in GPT. We believe this interpretation of neurons can further help to understand the general computation of deep neural networks.</p> <h2 id="linear-neurons-in-mlp">Linear Neurons in MLP</h2> <p>Let see the most basic module, weights in a linear layer. The weights are a matrix whose rows are the outputs for neurons and the columns for the synapses of these neurons. You can think that each row (neuron) computes independently the input signal $x$.</p> <p>With the assumption that $W \in \mathbb{R}^{\textcolor{red}{m} \times \textcolor{blue}{n}}$</p> <ul> <li>🌱 number of neurons : $\textcolor{red}{m}$</li> <li>🌱 number of synapses per a neuron : $\textcolor{blue}{n}$</li> <li>🌱 number of synapses in total : $\textcolor{red}{m} \times \textcolor{blue}{n}$</li> </ul> <p>MLP is a series of linear neurons with activations in between them. The activations are thresholds to pass the information with valid signals. For example, ReLU cuts negative signals and Tanh provides gating mechanisms of signals. Therefore, in the interpretation of neurons, we can think of activations as modifiers of neurons’s outputs.</p> <p>The Figure below shows two layer MLP. Each layer has two neurons and the neurons in the first layer have three synapses for each neuron, while the neurons in the second layer have two synapses for each neuron.</p> <figure style="text-align:left; display:block;width:100;"> <img src="/assets/img/neurons_in_deep_learning/linear.png" style="width:100%"> <figcaption> There are 2 neurons in each layer and 4 neurons in total. Synapses in a neuron computes dot-product with the input signals. </figcaption> </figure> <p>The Figure below shows the four layer MLP. In each layer, three neurons exist and each neuron has three synapses. Note that all the pre-neurons and post-neurons are connected with synapses. We think that is why MLP is called a densely connected neural network.</p> <figure style="text-align:left; display:block;width:100;"> <img src="/assets/img/neurons_in_deep_learning/mlp.png" style="width:100%"> <figcaption> An example of four layer MLP. The first panel shows weight perspectives, while the second panel shows neuron’s perspective. Note that all the neurons output only a single scalar respectively. </figcaption> </figure> <h2 id="convolutional-neuron">Convolutional Neuron</h2> <p>Convolutional layer is also considered as a linear layer as we can reformulate the convolution operation as a linear operation. However, we use another tool to interpret the convolutional neuron. The most frequent way of creating a convolutional layer is using the notation: (<code class="language-plaintext highlighter-rouge">out_channels</code>, <code class="language-plaintext highlighter-rouge">in_channels</code>, <code class="language-plaintext highlighter-rouge">kernel</code>, <code class="language-plaintext highlighter-rouge">kernel</code>, ..). With this notation, the <code class="language-plaintext highlighter-rouge">out_channels</code> parts are the same with the rows in the linear neuron and (<code class="language-plaintext highlighter-rouge">in_channels</code>, <code class="language-plaintext highlighter-rouge">kernel</code>, <code class="language-plaintext highlighter-rouge">kernel</code>) are the synapses for a neuron. With this interpretation, the only difference with the linear layer is (<code class="language-plaintext highlighter-rouge">kernel</code>, <code class="language-plaintext highlighter-rouge">kernel</code>) part where the convolution operation is applied in the 2D plane. If you assume that kernel size is 1, then you can think of a linear neuron!</p> <ul> <li>🌱 number of neurons : <code class="language-plaintext highlighter-rouge">out_channels</code> </li> <li>🌱 number of synapses per a neuron : <code class="language-plaintext highlighter-rouge">in_channels</code>$\times$ <code class="language-plaintext highlighter-rouge">kernel</code> $\times$ <code class="language-plaintext highlighter-rouge">kernel</code> </li> <li>🌱 number of synapses in total : <code class="language-plaintext highlighter-rouge">out_channels</code> $\times$ <code class="language-plaintext highlighter-rouge">in_channels</code> $ \times$ <code class="language-plaintext highlighter-rouge">kernel</code> $\times$ <code class="language-plaintext highlighter-rouge">kernel</code> </li> </ul> <hr> <h2 id="recurrent-neuron">Recurrent Neuron</h2> <p>Beside MLP and CNN, the other basic module is a recurrent neural network (RNN) which successively computes an input with linear operations in it with hidden states. Computationally, the recurrent neuron is the same with the linear neuron except input and output types. Note that the recurrent neuron should provide outputs which are re-injected to the input of that neuron. The advanced RNN modules such as LSTM <d-cite key="hochreiter1997long"></d-cite> and GRU <d-cite key="chung2014empirical"></d-cite> use the gating mechanism in them to process the long-term memory well. These architectures do not change the interpretation of neurons as they are combinations of linear neurons.</p> <hr> <h2 id="neurons-in-gpt-block">Neurons in GPT Block</h2> <p>Now we discuss neurons in more advanced architectures such as GPT. GPT consists of a token embedding module, transformer decoder blocks and task specific heads such as LMHead. We verify neurons in a GPT block and leave the interpretation of other modules as they are just linear-like neurons. GPT block has two main parts MLP and self-attention (or cross-attention), and layer-norm.</p> <h4 id="mlp">MLP</h4> <p>MLP block is a two layer MLP whose first layer is sometimes called key and second layer sometimes is called value. We use $d_{model}$ which is the dimension of GPT representations to describe the number of neurons and synapses. The key part is a linear layer with weight \(W_{key} \in \mathbb{R}^{\textcolor{red}{4\cdot d_{model}} \times \textcolor{blue}{d_{model}}}\) whose number of neurons is four times larger than the number of synapses. On the other hand the value part is a linear layer with weight \(W_{value} \in \mathbb{R}^{\textcolor{red}{ d_{model}} \times \textcolor{blue}{4\cdot d_{model}}}\) whose number of neurons is four times smaller than the number of synapses. Therefore, this architecture is a bottleneck architecture and many researchers interpret it as a neural memory.</p> <p>Consider $d_{model} = 12,288$ which is the hidden dimension size of GPT3 (175B).</p> <ul> <li>🌱 number of neurons : 49,152 (key neuron) + 12,288 (value neuron)</li> <li>🌱 number of synapses per a neuron : 12,288 (key neuron), 49,152 (value neuron)</li> <li>🌱 number of synapses in total : <strong>1,207,959,552</strong> <br> (= 49,152 $\times$ 12,288 (key neuron) + 12,288 $\times$ 49,152 (value neuron))</li> </ul> <h4 id="attn">ATTN</h4> <p>In ATTN, there are four linear layers: query, key, value, output and each layer has weight \(W \in \mathbb{R}^{\textcolor{green}{d_{model}} \times \textcolor{green}{d_{model}}}\). Therefore, we can easily interpret neurons in ATTN<d-footnote> If you assume QK, OV circuits, the number of neurons are reduce by 2 times. <d-cite key="elhage2021mathematical"></d-cite> </d-footnote>. Note that self-attention and cross-attention are about how to use these neurons and do not affect the interpretation of neurons</p> <p>Consider $d_{model} = 12,288$ which is the hidden dimension size of GPT3 (175B).</p> <ul> <li>🌱 number of neurons :<strong>61,440</strong> = 12,288 $\times$ 4 (Q, K, V, O)</li> <li>🌱 number of synapses per a neuron : : <strong>12,288</strong> (Q, K, V, O)</li> <li>🌱 number of synapses in total : <strong>603,979,776</strong> = (12,288 $\times$ 4) $\times$ 12,288</li> </ul> <hr> <h2 id="neurons-in-gpt3-175b">Neurons in GPT3 (175B)</h2> <p>Finally, we count the number of neurons and synapses in GPT3 (175B) blocks with the above interpretation<d-footnote> Caveats: We do not count the layer-norm in a block and the number of weights would not exactly match with the number of synapses in this case. Also, bias is a parameter in GPT, but is not counted for neuron and synapse. </d-footnote>. GPT3 has 96 blocks and each block has MLP whose number synapses is <strong>1,207,959,552</strong> and ATTN whose number of synapses is <strong>603,979,776</strong>. We can simply add these two and multiply 96 to compute the total number of synapses.</p> <ul> <li>🍀 (<code class="language-plaintext highlighter-rouge">GPT3</code>) number of synapses : <strong>173B</strong> <br> (173,946,175,488 = 96 $\times$ (1,207,959,552 + 603,979,776)) <d-footnote> 2B difference (175B and 173B) is due to bias, embedding, layer-norm and LM heads modules. </d-footnote> </li> <li>☘️ (<code class="language-plaintext highlighter-rouge">GPT3</code>) number of neurons : <strong>11M</strong> <br> (11,796,480 = 96 $\times$(61,440+61,440))</li> <li>☘️ (<code class="language-plaintext highlighter-rouge">GPT3</code>) number of synapses per a neuron : <strong>14,745</strong> </li> </ul> <p>As humans have 7,000 synapses per neuron, we can think that GPT3 has a similar number or even larger number of connections between neurons. However, humans have much more neurons compared to GPT. We believe such a difference can affect the general learning process. For example, if the number of neurons is large, we can see them as an ensemble of simple knowledge. On the other hand, if the number of synapses is large, expert neurons will provide knowledge.</p> <h2 id="conclusion">Conclusion</h2> <p>As we think more about a deep neural network with a metaphor to a human brain, the computational graph is highly interpretable and the individual components handle very simple computations like neurons in our brain. Recent work in interpretability is about discovering meanings of neurons and the work like this can shed light on the interpretation of the deep neural network. We believe still deep dissection of neural network can give better interpretation of deep neural networks.</p> <hr> <h2 id="differences-between-neuroscience-and-deep-learning">Differences between Neuroscience and Deep Learning</h2> <h3 id="rate-coding">Rate-coding</h3> <p>Biological neurons communicate via receiving and transmitting excitatory spikes. Having received multiple spikes, neuron is more likely to produce multiple spikes of its own. However, unlike in deep learning, biological neurons do not receive spikes simultaneously. Moreover, neuron rates may coincide, and synchronize between multiple neurons, which is not presented in the deep learning.</p> <figure style="text-align:left; display:block;width:100;"> <div style="display: flex; justify-content: center"> <img src="/assets/img/neurons_in_deep_learning/rate_coding.png" style="width:75%; margin: auto 0;"> </div> <figcaption> The key-neurons output scalars which are multiplied with weights (synapses) in the value-neurons. Then, the values neurons compute them (linear sum) to make a single output respectively. </figcaption> </figure> <h3 id="synaptic-strength">Synaptic strength</h3> <p>Spikes are not equal, since the after reaching axon terminal the amount of electrical energy strongly depends on the strength of the synapse. Therefore, with the same output signals from preceding neurons, the received signal may differ. Similarly, the strength of the signal in deep learning is usually presented by the weight of synapse.</p> <figure style="text-align:left; display:block;width:100;"> <img src="/assets/img/neurons_in_deep_learning/synaptic_strength.jpg" style="width:100%"> <figcaption> The key-neurons output scalars which are multiplied with weights (synapses) in the value-neurons. Then, the values neurons compute them (linear sum) to make a single output respectively. </figcaption> </figure> <h3 id="excitatory-and-inhibitory-neurotransmitters">Excitatory and inhibitory neurotransmitters</h3> <p>If biological neurons are examined closely, it becomes evident that there are two main classes of neurotransmitters <d-footnote>Elements, transmitted with signal </d-footnote>, namely excitatory, and inhibitory. The former ones are responsible for amplifying transmitted signal, while the latter decrease its strength. Although most of the neurons are excitatory, inhibitory neurons play crucial role in selecting, and routing information, preventing epileptic activity <d-footnote> Chaotic firing of many neurons in the network</d-footnote>.</p> <h3 id="conclusion-1">Conclusion</h3> <ul> <li>The deep learning neuron receives inputs, or activations, from other neurons. The activations are rate-coded representations of the spiking of biological neurons.</li> <li>The activations are multiplied by synaptic weights. These weights are models of synaptic strengths in biological neurons, and also model inhibitory transmission, in that the weights may take on negative values.</li> <li>The weighted activations are summed together, modeling the accumulation process that happens in the cell body of a biological neuron.</li> <li>A bias term is added to the sum, modeling the general sensitivity of neuron.</li> <li>Finally, the summed value is shaped by an activation function — typically one that limits the minimum or maximum output value (or both), such as a sigmoid function. This models the intrinsic minimum spiking rate of biological neurons (zero) or the maximum rate (due to details in the physiological mechanisms by which spikes are generated).</li> </ul> <h2 id="steps-to-match-biological-and-deep-learning-neurons">Steps to match Biological and Deep Learning Neurons</h2> <h3 id="temporal-coding">Temporal Coding</h3> <p>Deep learning relies on rate-based coding, in which each neuron’s activation is a single numeric value that models the average spiking rate in response to a given stimulus (be it from other neurons or from an external stimulus). The collective set of spiking rate values within a single layer of the network is typically organized as a vector of numbers, and this vector is referred to as the representation of an external stimulus, at that layer.</p> <p>The expressiveness of rate-based neural coding is much lower than that which is possible with neural codes (representations) based on the relative time between spikes on multiple neurons. As a simple example of the existence of this type of code in biology, consider the auditory system. When sound waves reach our ears, our brain processes them to determine the type of animal, object, or phenomenon that produced the sound, but also to estimate the direction from which the sound came (localization). One way in which sound location is determined is based on the fact that sounds from the right will reach the right ear first, then the left ear. Auditory neurons close to the right and left ears exhibit spike timing that reflects this acoustic timing difference. Auditory neurons the are more medially located (near the midline of the body) receive input from neurons near both ears and are selective for the location of the sound, thanks to this temporal coding.</p> <figure style="text-align:left; display:block;width:100;"> <img src="/assets/img/neurons_in_deep_learning/ear_processing.png" style="width:100%"> <figcaption> The key-neurons output scalars which are multiplied with weights (synapses) in the value-neurons. Then, the values neurons compute them (linear sum) to make a single output respectively. </figcaption> </figure> <p>More generically, consider the simple example of a single neuron receiving input from two other neurons, each of which send identical input: a short train of N uniformly spaced (in time) excitatory spikes over 100 ms. All else being equal, this will generate some stereotypical response in the receiving neuron. In contrast, if one of the input neurons sent all if its spikes in the first 20 ms (of the 100 ms interval), and the other input neuron sent all of its spikes in the final 20 ms, the response of the receiving neuron is likely to be notably different. Thus, even though the spiking-rate of the input neurons is identical in each scenario (10N spikes/sec) the temporal coding is quite different, and the response of the receiving neuron can be quite different as well. Importantly, there can exist many input-output combinations when using a temporal code, even when the number of input spikes is low, constant, or both. This is what we mean by a more expressive coding scheme. In regards to AI, a model that utilizes temporal coding can conceivably perform much more complex tasks than a deep learning model with the same number of neurons.</p> <figure style="text-align:left; display:block;width:100;"> <div style="display: flex; justify-content: center"> <img src="/assets/img/neurons_in_deep_learning/temporal_coding.png" style="width:75%"> </div> <figcaption> The key-neurons output scalars which are multiplied with weights (synapses) in the value-neurons. Then, the values neurons compute them (linear sum) to make a single output respectively. </figcaption> </figure> <h3 id="inhibitory-neurons">Inhibitory neurons</h3> <p>Based on our simple description of biological and deep learning neurons, the distinction between excitatory and inhibitory neurons can be mimicked by deep learning neurons. Namely, one can mimic a biological inhibitory neuron simply by ensuring its deep learning equivalent has negative values for all synaptic weights between its axons and the dendrites of neurons to which it projects. Conversely, when mimicking a biological excitatory neuron, such synapses should always have positive weights. However, training and implementation will be easier if one simply requires that all synapses are positive-valued (perhaps by applying a ReLU function to the weights after each training iteration), and use an activation function that produces negative (positive) values for the inhibitory (excitatory) neurons.</p> <p>It’s not certain, but one possibility is that the use of explicit inhibitory neurons helps to constrain the overall parameter space while allowing for the evolution or development of sub-network structures that promote fast learning. In biological systems, it is not necessary for the brain to be able to learn any input-output relationship, or execute any possible spiking sequence. We live in a world with fixed physical laws, with species whose individual members share many common within-species behavioral traits that need not be explicitly learned. Limiting the possible circuit connectivity and dynamic activity of a network is tantamount to limiting the solution space over which a training method must search.</p> <p>Another potential benefit of inhibitory neurons, related to the use of structured canonical circuits as just mentioned, is that inhibitory neurons may effectively “gate off” large numbers of neurons that are unnecessary for processing of a given sample or task, thereby lowering energy requirements.</p> <h3 id="low-energy-spike-based-hardware">Low-energy spike-based hardware</h3> <p>The energy efficiency of biological neurons, relative to conventional computing hardware, is largely due to two characteristics of these neurons. Firstly, biological neurons transmit only short bursts of analog energy (spikes) rather than maintaining many bits that represent a single floating-point or integer number. In conventional hardware, these bits require persistent energy flow to maintain the 0 or 1 state, unless much slower types of memory are used (non-volatile RAM).</p> <p>Secondly, memory is co-located with processing in biological neurons. That is, the synaptic strengths are the long-term memory of the network (recurrent connectivity can maintain short-term memory, but that’s a topic for some other post), they are involved in the processing (spike weighting and transmission), and are very close to other aspects of the processing (energy accumulation in the cell body). In contrast, conventional hardware is regularly transmitting bits from RAM to the processor — a considerable distance and a considerable energy drain.</p> <hr> <h2 id="appendix-interpret-key-neurons-and-value-neurons">(Appendix) Interpret Key Neurons and Value Neurons</h2> <p>In the MLP section, we discuss the key-value neurons. In this section, we provide more detailed neuron-perspectives on these modules. The Figure below shows key-value computation with sizes, 3 for input, 8 for key, and 2 for value neurons <d-footnote> We use 3 for the better visualization of the input, which is originally 2 in GPT. </d-footnote>.</p> <figure style="text-align:left; display:block;width:100;"> <img src="/assets/img/neurons_in_deep_learning/key-value.png" style="width:100%"> <figcaption> The key-neurons output scalars which are multiplied with weights (synapses) in the value-neurons. Then, the values neurons compute them (linear sum) to make a single output respectively. </figcaption> </figure> <p>If we just assume that a neuron just provide a single output, we can interpret a neuron in a row-wise manner. That is, we don’t think about the meaning of weights and just consider the output value of each neuron. The Figure below shows the neuron-wise interpretation.</p> <figure style="text-align:left;"> <img src="/assets/img/neurons_in_deep_learning/neuron_inter.png" style="width:100%"> <figcaption> The row-wise neuron interpretation. As a single neuron has multiple synapses, the aggregated signal will go out and further be cut with activations. </figcaption> </figure> <p>Unlike the neuron-wise interpretation where we interpret each neuron separately, we usually interpret multiple neurons together by considering the directional vector. In this case, the weights in value-neurons are not just used for aggregation of synapses, but could be interpreted by directionally meaningful information. The Figure below shows the example. In this case, the key is used to scale the vectors.</p> <figure style="text-align:left;"> <img src="/assets/img/neurons_in_deep_learning/value_inter.png" style="width:100%"> <figcaption> Column-interpretation of neurons. It is more natural to think a weight matrix as directional vectors. The key-neurons output scales for the directional vectors. </figcaption> </figure> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/all.bib"></d-bibliography><div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"team-interpret/team-interpret","data-repo-id":"R_kgDOKCB5Vw","data-category":"Q&A","data-category-id":"DIC_kwDOKCB5V84CYQ_P","data-mapping":"title","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 SAIL Team Interpretability. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>